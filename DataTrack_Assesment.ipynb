{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1:\n",
        "Identify the sentence that is being repeated in a document.\n"
      ],
      "metadata": {
        "id": "dagSEBPfpzoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"\"\"\n",
        "She made an attempt to straighten her tawny hair. Her voice quavered with emotion. “You must be a very lonely man, Judge Seagrave.” the sentence is present in the doc that is repeating. How is it?  Then she turned a gaze on him that might have ignited a rain-sodden haystack. “And I’m a lonely woman.”\n",
        "\n",
        "It might be merely descriptive: Lines of weeds criss-crossed the cracked parking lot of the Seashell Motor Courts. The flaking paint on the buildings had chalked to a pastel pink on walls covered with graffiti. Many of the windows had been smashed out. How is it? Where the sign had been, atop rusting steel posts, only the metal outline of a seashell remained.\n",
        "\n",
        "It might have action but no dialogue: It was Ms. Fitzhugh. She was walking fast. A strange expression crossed the faces of the students as they glanced toward the door and saw the principal go straight into the boys’ restroom. the sentence is present in the doc that is repeating. The footsteps stopped. There was a deep, throaty sound difficult to describe. Then came an eruption of shrill screaming and a rapid sound of heels. Moments later, Ms. Fitzhugh emerged, her eyes wild. Screaming, she skidded in the hall and headed toward the office.\n",
        "\n",
        "It might be expository: Above ground was the medieval settlement of Skaar’s Outpost, originally a fort to guard the cave entrance. Its inception as a town had been in the lodging and supply needs of explorers there to attempt the subterranean labyrinth when it had opened as a commercial venture. How is it? With the caverns’ flooding and subsequent closure, however, Skaar’s Outpost had declined into an agricultural community miles from any trade routes.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "5sHQCp4Wp6Ng"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2lDGnDVqKYv",
        "outputId": "6d27ac1f-5f59-4f72-8fa7-2ca65bc4400e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hDpoByULpwca"
      },
      "outputs": [],
      "source": [
        "sentences = sent_tokenize(document)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repeated_sentences = {}\n",
        "for sentence in sentences:\n",
        "    sentence = sentence.strip()\n",
        "    if sentence in repeated_sentences:\n",
        "        repeated_sentences[sentence] += 1\n",
        "    else:\n",
        "        repeated_sentences[sentence] = 1"
      ],
      "metadata": {
        "id": "vIPkvdE8qfJM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repeated_more_than_once = {sentence: count for sentence, count in repeated_sentences.items() if count > 1}\n",
        "print(repeated_more_than_once)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JptI2r9hqu5L",
        "outputId": "fbce22df-8e3a-4934-c90a-9368015ee310"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'How is it?': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gavQzWZ5tX7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Document has 5 tablee. In that 2 tables columns are similar semantically ie., profit and gain and gain and loss. figuring out that 2 tables that are matching semantically**"
      ],
      "metadata": {
        "id": "jTR77j81s814"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "table1 = pd.DataFrame({'Profit': [1000, 800],'Sales': [10000, 8000]})\n",
        "table2 = pd.DataFrame({'Loss': [500, 300],'Deprivation': [200, 100]})\n",
        "table3 = pd.DataFrame({'Gain': [500, 300],'Revenue_from_sales': [2000, 1500]})\n",
        "table4 = pd.DataFrame({'Name': ['sush', 'san'],'Email': ['sush@example.com', 'san@example.com']})\n",
        "table5 = pd.DataFrame({'Networth': ['32.3M', '425.M'],'Policy': ['avks', 'dkfn']})\n",
        "print(\"Table 1\")\n",
        "print(table1)\n",
        "print(\"\\nTable 2\")\n",
        "print(table2)\n",
        "print(\"\\nTable 3\")\n",
        "print(table3)\n",
        "print(\"\\nTable 4\")\n",
        "print(table4)\n",
        "print(\"\\nTable 5\")\n",
        "print(table5)\n",
        "tables = [table1, table2, table3, table4, table5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcqS5aTwrMYq",
        "outputId": "c79d0cdd-d387-462a-b09e-f805ee3c7382"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table 1\n",
            "   Profit  Sales\n",
            "0    1000  10000\n",
            "1     800   8000\n",
            "\n",
            "Table 2\n",
            "   Loss  Deprivation\n",
            "0   500          200\n",
            "1   300          100\n",
            "\n",
            "Table 3\n",
            "   Gain  Revenue_from_sales\n",
            "0   500                2000\n",
            "1   300                1500\n",
            "\n",
            "Table 4\n",
            "   Name             Email\n",
            "0  sush  sush@example.com\n",
            "1   san   san@example.com\n",
            "\n",
            "Table 5\n",
            "  Networth Policy\n",
            "0    32.3M   avks\n",
            "1    425.M   dkfn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "column_names = [col for table in tables for col in table.columns]\n",
        "print(column_names)\n",
        "sentences = []\n",
        "for col1 in column_names:\n",
        "    for col2 in column_names:\n",
        "        sentences.append([col1.lower(), col2.lower()])\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ViXcEfStqqV",
        "outputId": "44b596dd-9eb2-457b-9093-79eebbfc0343"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Profit', 'Sales', 'Loss', 'Deprivation', 'Gain', 'Revenue_from_sales', 'Name', 'Email', 'Networth', 'Policy']\n",
            "[['profit', 'profit'], ['profit', 'sales'], ['profit', 'loss'], ['profit', 'deprivation'], ['profit', 'gain'], ['profit', 'revenue_from_sales'], ['profit', 'name'], ['profit', 'email'], ['profit', 'networth'], ['profit', 'policy'], ['sales', 'profit'], ['sales', 'sales'], ['sales', 'loss'], ['sales', 'deprivation'], ['sales', 'gain'], ['sales', 'revenue_from_sales'], ['sales', 'name'], ['sales', 'email'], ['sales', 'networth'], ['sales', 'policy'], ['loss', 'profit'], ['loss', 'sales'], ['loss', 'loss'], ['loss', 'deprivation'], ['loss', 'gain'], ['loss', 'revenue_from_sales'], ['loss', 'name'], ['loss', 'email'], ['loss', 'networth'], ['loss', 'policy'], ['deprivation', 'profit'], ['deprivation', 'sales'], ['deprivation', 'loss'], ['deprivation', 'deprivation'], ['deprivation', 'gain'], ['deprivation', 'revenue_from_sales'], ['deprivation', 'name'], ['deprivation', 'email'], ['deprivation', 'networth'], ['deprivation', 'policy'], ['gain', 'profit'], ['gain', 'sales'], ['gain', 'loss'], ['gain', 'deprivation'], ['gain', 'gain'], ['gain', 'revenue_from_sales'], ['gain', 'name'], ['gain', 'email'], ['gain', 'networth'], ['gain', 'policy'], ['revenue_from_sales', 'profit'], ['revenue_from_sales', 'sales'], ['revenue_from_sales', 'loss'], ['revenue_from_sales', 'deprivation'], ['revenue_from_sales', 'gain'], ['revenue_from_sales', 'revenue_from_sales'], ['revenue_from_sales', 'name'], ['revenue_from_sales', 'email'], ['revenue_from_sales', 'networth'], ['revenue_from_sales', 'policy'], ['name', 'profit'], ['name', 'sales'], ['name', 'loss'], ['name', 'deprivation'], ['name', 'gain'], ['name', 'revenue_from_sales'], ['name', 'name'], ['name', 'email'], ['name', 'networth'], ['name', 'policy'], ['email', 'profit'], ['email', 'sales'], ['email', 'loss'], ['email', 'deprivation'], ['email', 'gain'], ['email', 'revenue_from_sales'], ['email', 'name'], ['email', 'email'], ['email', 'networth'], ['email', 'policy'], ['networth', 'profit'], ['networth', 'sales'], ['networth', 'loss'], ['networth', 'deprivation'], ['networth', 'gain'], ['networth', 'revenue_from_sales'], ['networth', 'name'], ['networth', 'email'], ['networth', 'networth'], ['networth', 'policy'], ['policy', 'profit'], ['policy', 'sales'], ['policy', 'loss'], ['policy', 'deprivation'], ['policy', 'gain'], ['policy', 'revenue_from_sales'], ['policy', 'name'], ['policy', 'email'], ['policy', 'networth'], ['policy', 'policy']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(sentences, vector_size=5, window=3, min_count=1)\n",
        "similar_columns = {}\n",
        "for col1 in column_names:\n",
        "    for col2 in column_names:\n",
        "        if col1 != col2:\n",
        "            try:\n",
        "                similarity = model.wv.similarity(col1.lower(), col2.lower())\n",
        "                if similarity > 0.5:\n",
        "                    similar_columns[(col1, col2)] = similarity\n",
        "            except KeyError:\n",
        "                pass\n",
        "for (col1, col2), similarity in similar_columns.items():\n",
        "    print(f\"Similar columns: {col1} and {col2} (similarity: {similarity:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzGOL2jyz8Wb",
        "outputId": "f15bf9f6-a8e4-4517-c4a5-85c526a464d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar columns: Sales and Loss (similarity: 0.67)\n",
            "Similar columns: Loss and Sales (similarity: 0.67)\n",
            "Similar columns: Deprivation and Gain (similarity: 0.93)\n",
            "Similar columns: Deprivation and Name (similarity: 0.55)\n",
            "Similar columns: Deprivation and Networth (similarity: 0.85)\n",
            "Similar columns: Gain and Deprivation (similarity: 0.93)\n",
            "Similar columns: Gain and Name (similarity: 0.77)\n",
            "Similar columns: Gain and Networth (similarity: 0.77)\n",
            "Similar columns: Name and Deprivation (similarity: 0.55)\n",
            "Similar columns: Name and Gain (similarity: 0.77)\n",
            "Similar columns: Name and Networth (similarity: 0.62)\n",
            "Similar columns: Networth and Deprivation (similarity: 0.85)\n",
            "Similar columns: Networth and Gain (similarity: 0.77)\n",
            "Similar columns: Networth and Name (similarity: 0.62)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec([column_names], vector_size=5, window=3, min_count=1)\n",
        "similarities = []\n",
        "def average_similarity(table1, table2):\n",
        "    similarities = []\n",
        "    for col1 in table1.columns:\n",
        "        for col2 in table2.columns:\n",
        "            try:\n",
        "                similarity = model.wv.similarity(col1.lower(), col2.lower())\n",
        "                similarities.append(similarity)\n",
        "                print(f\"Similarity between '{col1}' and '{col2}': {similarity:.2f}\")  # Debug output\n",
        "            except KeyError:\n",
        "                continue\n",
        "    return sum(similarities) / len(similarities) if similarities else 0"
      ],
      "metadata": {
        "id": "TKaIlGrzpI40"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.9\n",
        "pair_similar_table = []\n",
        "for i in range(len(tables)):\n",
        "    for j in range(i + 1, len(tables)):\n",
        "        similarity = average_similarity(tables[i], tables[j])\n",
        "        print(f\"Average similarity between Table {i} and Table {j}: {similarity:.2f}\")\n",
        "        if similarity > threshold:\n",
        "            pair_similar_table.append((i, j, similarity))"
      ],
      "metadata": {
        "id": "BRcBYqzzG0YU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9903608a-8d61-489b-f8dd-1a20ffe4aa25"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average similarity between Table 0 and Table 1: 0.00\n",
            "Average similarity between Table 0 and Table 2: 0.00\n",
            "Average similarity between Table 0 and Table 3: 0.00\n",
            "Average similarity between Table 0 and Table 4: 0.00\n",
            "Average similarity between Table 1 and Table 2: 0.00\n",
            "Average similarity between Table 1 and Table 3: 0.00\n",
            "Average similarity between Table 1 and Table 4: 0.00\n",
            "Average similarity between Table 2 and Table 3: 0.00\n",
            "Average similarity between Table 2 and Table 4: 0.00\n",
            "Average similarity between Table 3 and Table 4: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if pair_similar_table:\n",
        "    for i, j, similarity in pair_similar_table:\n",
        "        print(f\"Tables {i} and {j} are similar (similarity: {similarity:.2f})\")\n",
        "        print(f\"Table {i} columns: {tables[i].columns}\")\n",
        "        print(f\"Table {j} columns: {tables[j].columns}\")\n",
        "else:\n",
        "    print(\"No table pairs are similar with above the threshold.\")"
      ],
      "metadata": {
        "id": "wYrzwuzoG1gl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b413c84a-467c-4afe-8ff7-acbbf9663276"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No table pairs are similar with above the threshold.\n"
          ]
        }
      ]
    }
  ]
}